from fastapi import FastAPI, UploadFile, File
from models import Question, CompareRequest, CompareResponse
import requests
import os
import google.generativeai as genai
from typing import Dict
from dotenv import load_dotenv  # <-- Add this

load_dotenv()  # <-- Load environment variables from .env

app = FastAPI()

# 1. Whisper Integration (Voice to Text)
import whisper

@app.post("/voice-to-text/")
async def voice_to_text(audio: UploadFile = File(...)):
    """
    Accepts an audio file and returns the transcribed text using local Whisper (free).
    """
    contents = await audio.read()
    temp_filename = "temp_audio.wav"
    with open(temp_filename, "wb") as f:
        f.write(contents)

    try:
        model = whisper.load_model("base")  # You can use "tiny", "base", "small", "medium", "large"
        result = model.transcribe(temp_filename)
        os.remove(temp_filename)
        return {"text": result["text"]}
    except Exception as e:
        os.remove(temp_filename)
        return {"text": f"Error processing Whisper locally: {str(e)}"}
    
# 2. Gemini Expected Answer Generator

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=GEMINI_API_KEY)

@app.post("/expected-answer/")
async def expected_answer(data: Question):
    """
    Accepts a question and returns the expected answer generated by Gemini.
    """
    prompt = (
        f"Give a technical expected answer to the following interview question:\nQuestion: {data.question}"
    )
    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        expected = response.text.strip()
        return {"expected_answer": expected}
    except Exception as e:
        return {"expected_answer": f"Error processing Gemini response: {str(e)}"}

# 3. Gemini Answer Comparator (Score & Feedback)
@app.post("/compare/", response_model=CompareResponse)
async def compare_answers(data: CompareRequest):
    """
    Compares the user's answer with the expected answer using Gemini and returns scores and feedback.
    """
    prompt = (
        "You are an interview evaluator. Compare the expected answer and user's answer.\n"
        "- Give a domain-wise score out of 100.\n"
        "- Give detailed feedback on what was missing or could be improved.\n"
        "Return a JSON with 'domain_scores' and 'feedback'.\n"
        f"Domain: Deep Learning\n"
        f"Question: {data.question}\n"
        f"Expected Answer: {data.expected_answer}\n"
        f"User Answer: {data.user_answer}"
    )

    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        import json
        import re

        # Try to extract JSON from the response text
        model_text = response.text
        json_match = re.search(r'\{.*\}', model_text, re.DOTALL)
        if json_match:
            parsed = json.loads(json_match.group())
            domain_scores = parsed.get("domain_scores", {})
            feedback = parsed.get("feedback", "")
        else:
            domain_scores = {}
            feedback = model_text

        return {
            "domain_scores": domain_scores,
            "feedback": feedback
        }
    except Exception as e:
        return {
            "domain_scores": {},
            "feedback": f"Error processing Gemini response: {str(e)}"
        }
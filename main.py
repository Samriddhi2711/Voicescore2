from fastapi import FastAPI, UploadFile, File
from models import Question, CompareRequest, CompareResponse
import os
import google.generativeai as genai
from typing import Dict
from dotenv import load_dotenv  # <-- Add this
import requests  # <-- Add this
from fastapi.middleware.cors import CORSMiddleware


load_dotenv()  # <-- Load environment variables from .env

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Yahan apne frontend ka URL bhi de sakte hain, e.g. ["http://localhost:3000"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 1. Whisper Integration (Voice to Text)
import whisper
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

@app.post("/voice-to-text/")
async def voice_to_text(audio: UploadFile = File(...)):
    """
    Accepts an audio file and returns the transcribed text using OpenAI Whisper API (paid).
    """
    contents = await audio.read()
    temp_filename = "temp_audio.wav"
    with open(temp_filename, "wb") as f:
        f.write(contents)
    print("Audio file saved at:", os.path.abspath(temp_filename))

    try:
        with open(temp_filename, "rb") as audio_file:
            response = requests.post(
                "https://api.openai.com/v1/audio/transcriptions",
                headers={"Authorization": f"Bearer {OPENAI_API_KEY}"},
                files={"file": audio_file},
                data={"model": "whisper-1"}
            )
        os.remove(temp_filename)
        if response.status_code == 200:
            text = response.json()["text"]
            return {"text": text}
        else:
            return {"text": f"OpenAI API Error: {response.text}"}
    except Exception as e:
        if os.path.exists(temp_filename):
            os.remove(temp_filename)
        return {"text": f"Error processing Whisper API: {str(e)}"}

    
# 2. Gemini Expected Answer Generator

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=GEMINI_API_KEY)

@app.post("/expected-answer/")
async def expected_answer(data: Question):
    """
    Accepts a question and returns the expected answer generated by Gemini.
    """
    prompt = (
        f"Give a technical expected answer to the following interview question:\nQuestion: {data.question}"
    )
    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        expected = response.text.strip()
        return {"expected_answer": expected}
    except Exception as e:
        return {"expected_answer": f"Error processing Gemini response: {str(e)}"}

# 3. Gemini Answer Comparator (Score & Feedback)
@app.post("/compare/", response_model=CompareResponse)
async def compare_answers(data: CompareRequest):
    """
    Compares the user's answer with the expected answer using Gemini and returns scores and feedback.
    """
    prompt = (
        "You are an interview evaluator. Compare the expected answer and user's answer.\n"
        "- Give a domain-wise score out of 100.\n"
        "- Give detailed feedback on what was missing or could be improved.\n"
        "Return a JSON with 'domain_scores' and 'feedback'.\n"
        f"Domain: Deep Learning\n"
        f"Question: {data.question}\n"
        f"Expected Answer: {data.expected_answer}\n"
        f"User Answer: {data.user_answer}"
    )

    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        import json
        import re

        # Try to extract JSON from the response text
        model_text = response.text
        json_match = re.search(r'\{.*\}', model_text, re.DOTALL)
        if json_match:
            parsed = json.loads(json_match.group())
            domain_scores = parsed.get("domain_scores", {})
            feedback = parsed.get("feedback", "")
        else:
            domain_scores = {}
            feedback = model_text

        return {
            "domain_scores": domain_scores,
            "feedback": feedback
        }
    except Exception as e:
        return {
            "domain_scores": {},
            "feedback": f"Error processing Gemini response: {str(e)}"
        }